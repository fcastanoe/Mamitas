# Thermomatter AI
Este repositorio contiene un modelo de segmentaciÃ³n para dermatomas podales basado en imÃ¡genes tÃ©rmicas. Su objetivo principal es proporcionar herramientas y recursos para la segmentaciÃ³n de regiones especÃ­ficas del pie, utilizando tÃ©cnicas de aprendizaje profundo.

---

## ğŸ“ Estructura de Carpetas

```
â”œâ”€â”€ App/ # CÃ³digo fuente de la aplicaciÃ³n mÃ³vil
â”œâ”€â”€ Base_de_Datos/ # Conjunto de datos tÃ©rmicos (30 casos) y scripts de preprocesamiento
â”œâ”€â”€ Models/ # Enlaces a modelos entrenados en Kaggle (>25â€¯MB)
â”œâ”€â”€ notebooks/ # Jupyter notebooks de entrenamiento, inferencia y anÃ¡lisis
â””â”€â”€ README.md # DocumentaciÃ³n principal (este archivo)
```

### 1. App/

Contiene todo lo generado por Android Studio y Chaquopy para la aplicaciÃ³n mÃ³vil:

- Archivos Kotlin (`.kt`)
- Scripts Python (`.py`) integrados con Chaquopy
- Archivos de configuraciÃ³n Gradle

> **Nota**: Usamos el plugin de Chaquopy para ejecutar scripts de Python dentro de la app, lo que facilita:
> - El uso de OCR para extraer regiones de interÃ©s  
> - La aplicaciÃ³n de registro no rÃ­gido para alinear secuencias  
> - La carga y ejecuciÃ³n de modelos `.tflite`

### 2. Base_de_Datos/

Incluye los **30 casos** de imÃ¡genes tÃ©rmicas originales y mÃ¡scaras de segmentaciÃ³n:

```
â”œâ”€â”€ ImÃ¡genes/
â””â”€â”€ Mascaras - Manuales/
â””â”€â”€ Mascaras - Red/

```

Estos datos sirvieron para entrenar y validar los modelos de segmentaciÃ³n.

### 3. Models/

AquÃ­ encontrarÃ¡s un archivo `models.md` con enlaces a los modelos entrenados y alojados en Kaggle (GitHub no acepta archivos >25â€¯MB):

- **ResUNet + EfficientNetB3 (.tflite)**: mejor combinaciÃ³n de mÃ©tricas usada en la app  
- ResUNet + ResNet34  
- YOLOv11 (segmentaciÃ³n y detecciÃ³n)

### 4. notebooks/

#### **ResUNet/Resnet34:**
- **resunet-resnet34-mamitas-train:**  
  Cuaderno para entrenar el modelo con arquitectura ResUNet con Backbone de Resnet34 para segmentaciÃ³n de pies.
- **resunet-resnet34-mamitas-test:**  
  Cuaderno para realizar inferencia con el modelo ResUNet con Backnone de Resnet34 entrenado.

#### **ResUNet/EfficientnetB3:**
- **resunet-efficientnetb3-mamitas-train:**  
  Cuaderno para entrenar el modelo con arquitectura ResUNet con Backbone de EfficientnetB3 para segmentaciÃ³n de pies.
- **resunet-efficientenetb3-mamitas-test:**  
  Cuaderno para realizar inferencia con el modelo ResUNet con Backnone de EfficientnetB3 entrenado.

#### **YOLOv11 - Segmentation:**
- **yolov11-mamitas-seg-train:**  
  Cuaderno para entrenar YOLOv11 para segmentaciÃ³n de pies.
- **yolov11-mamitas-seg-test-and-metrics:**  
  Cuaderno para realizar inferencia con el modelo YOLOv11 entrenado y sacar las metricas de Dice, Jaccard, Sensitivity, Specificity.

#### **YOLOv11 - Detection:**
- **yolov11-mamitas-obj-dect-train:**  
  Cuaderno para entrenar YOLOv11 para detecciÃ³n de pies.
- **yolov11-mamitas-seg-test-and-metrics:**  
  Cuaderno para realizar inferencia con el modelo YOLOv11 de detecciÃ³n entrenado.

#### **AnÃ¡lisis TÃ©rmico y Registro No RÃ­gido**  
- **mamitas-map-dermatomes-and-temperature.ipynb:**  
  implementaciÃ³n de OCR + alineamiento no rÃ­gido y grÃ¡ficas de evoluciÃ³n de temperatura vs. tiempo.

---

## ğŸš€ Requisitos

- Android Studio (proyecto Kotlin + Chaquopy)  
- Python â‰¥3.10  
- TensorFlow â‰¥2.15  
- PyTorch (YOLOv11)  
- OpenCV, NumPy, Matplotlib  
- Kaggle API & Roboflow API  
- Ultralytics (YOLOv11)

> Chaquopy ya viene configurado en el `build.gradle` de la carpeta `App/`.

---

## âš™ï¸ Uso

### 1. AplicaciÃ³n MÃ³vil, Codigo (App/)

1. Abre el proyecto en Android Studio.  
2. AsegÃºrate de tener conexiÃ³n a Internet para descargar dependencias de Chaquopy.  
3. Compila y ejecuta en un dispositivo o emulador con cÃ¡mara.  
4. La app capturarÃ¡ la zona plantar, ejecutarÃ¡ OCR y regresarÃ¡ la segmentaciÃ³n usando el modelo `.tflite`.

### 2. AplicaciÃ³n MÃ³vil - InstalaciÃ³n (App/)

1. Ve a la carpeta de App/apk/ en tu telefono
2. Descarga la apk
3. Abrela e instala la aplicaciÃ³n

### 3. Notebooks (Local o Kaggle)

1. Clona el repo:
   ```bash
   git clone https://github.com/tu_usuario/mamitas.git
   cd mamitas/notebooks

2. Instala requisitos:
   ```bash
   pip install -r requirements.txt

3. Ejecuta el notebook de tu interÃ©s:

- Entrenamiento: guarda pesos en Models/
- Inferencia: inserta tus imÃ¡genes en datasets/Mamitas/...
- AnÃ¡lisis tÃ©rmico: abre mamitas-map-dermatomes-and-temperature.ipynb

---

### **Inferencia**
1. Una vez entrenado el modelo o si decides utilizar uno preentrenado, abre el cuaderno de inferencia correspondiente.
2. AsegÃºrate de tener las imÃ¡genes de prueba organizadas en la carpeta correcta (para ResUNet: `./datasets/Mamitas/Test/images/`; para YOLOv11, se usarÃ¡ el archivo de configuraciÃ³n `data.yaml` generado durante el proceso de descarga).
3. Ejecuta el cuaderno para obtener los resultados de segmentaciÃ³n.

## Estructura de Datos

Los cuadernos esperan que los datos estÃ©n organizados de la siguiente manera:

```plaintext
datasets/ 
â””â”€â”€ Mamitas/
  â”œâ”€â”€ Train/
  â”‚ â”œâ”€â”€ images/
  â”‚ â””â”€â”€ masks/
  â”œâ”€â”€ Valid/
  â”‚ â”œâ”€â”€ images/
  â”‚ â””â”€â”€ masks/
  â”œâ”€â”€ Test/
  â”‚ â”œâ”€â”€ images/
  â”‚ â””â”€â”€ masks/
```

Para YOLOv11, la estructura es ligeramente diferente y se configura mediante el archivo `data.yaml` que se genera al descargar el dataset.

---

## Resultados

A continuaciÃ³n, se muestran algunas mÃ©tricas de rendimiento para segmentaciÃ³n y para detecciÃ³n en el modelo YOLO que se han obtenido en el proyecto para la segmentaciÃ³n de pies:

#### MÃ‰TRICAS DE SEGMENTACIÃ“N

| Modelo                     | Variante     | Dice Coefficient | Jaccard Index | Sensitivity | Specificity | 
|----------------------------|--------------|------------------|---------------|-------------|-------------|
| **ResUNet/Resnet34**       | default      | 0.96213          | 0.92907       | 0.96298     | 0.96298     |
| **ResUNet/EffcientenetB3** | default      | 0.98637          | 0.97333       | 0.98698     | 0.98698     |  
| **YOLOv11/Segmentation**   | segmentation | 0.98236          | 0.96535       | 0.99157     | 0.99216     | 

#### MÃ‰TRICAS DE DETECCIÃ“N

| Modelo                 | Variante     | Precision (P) | Recall (R) | mAP50   | mAP50-95 |
|------------------------|--------------|---------------|------------|---------|----------|
| **YOLOv11/Detection**  | segmentation |  1            | 1          |  0.995  |  0.995   |

Los cuadernos incluyen visualizaciones de los resultados de entrenamiento y ejemplos de inferencia. Los modelos entrenados se guardan en la carpeta `./models/` y los resultados de evaluaciÃ³n se almacenan en `./results/`.

---

## ImÃ¡genes Ilustrativas

A continuaciÃ³n se presentan ejemplos visuales del proceso completo:

- Imagen de Entrada:

<img src="https://github.com/user-attachments/assets/65c4cb95-0a0c-4d8c-9966-a851138ed690" alt="t20_caso22" width="400"/>

- DetecciÃ³n:

<img src="https://github.com/user-attachments/assets/991b601a-94e4-476d-9894-1046e7965594" alt="detection_feet" width="400" height="300"/>

- SegmentaciÃ³n:

<img src="https://github.com/user-attachments/assets/75911525-da8f-4b11-8e3c-5251f2429d06" alt="segmentation_feet" width="400" height="300"/>

---

## Base de datos
[Datos roboflow](https://universe.roboflow.com/mamitas/thermal-feet/browse?queryText=&pageSize=50&startingIndex=0&browseQuery=true)

---

## Contribuciones
Â¡Las contribuciones son bienvenidas! Si encuentras errores o tienes sugerencias para mejorar estos cuadernos, por favor abre un issue o envÃ­a una pull request.

---

## Licencia

Este proyecto se distribuye bajo la licencia BSD 2-Clause. Consulta el archivo LICENSE para mÃ¡s detalles.

Â¡Listo para segmentar dermatomas podales con tÃ©cnicas de aprendizaje profundo! ğŸ‘£ğŸ”¥

